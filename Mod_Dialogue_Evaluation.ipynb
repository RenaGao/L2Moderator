{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define scoring functions for interactivity aspects\n",
    "def score_topic_management(texts):\n",
    "    coherent_topic_words = ['furthermore', 'in addition', 'moreover', 'continuing', 'on the topic']\n",
    "    transitions = sum(any(word in text.lower() for word in coherent_topic_words) for text in texts)\n",
    "    if transitions >= len(texts) * 0.5:\n",
    "        return 5\n",
    "    elif transitions >= len(texts) * 0.3:\n",
    "        return 4\n",
    "    elif transitions >= len(texts) * 0.2:\n",
    "        return 3\n",
    "    elif transitions >= len(texts) * 0.1:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def score_tone_appropriateness(texts):\n",
    "    positive_tone_words = ['please', 'thank you', 'appreciate', 'great', 'good', 'nice']\n",
    "    negative_tone_words = ['annoyed', 'angry', 'frustrated', 'bad', 'hate']\n",
    "    positive_count = sum(any(word in text.lower() for word in positive_tone_words) for text in texts)\n",
    "    negative_count = sum(any(word in text.lower() for word in negative_tone_words) for text in texts)\n",
    "    if positive_count > negative_count and negative_count == 0:\n",
    "        return 5\n",
    "    elif positive_count >= negative_count:\n",
    "        return 4\n",
    "    elif negative_count > 0 and positive_count == 0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "\n",
    "def score_conversation_opening(text):\n",
    "    opening_words = ['welcome', 'good', 'today', 'start', 'introduce', 'let\\'s begin','hello']\n",
    "    if any(word in text.lower() for word in opening_words):\n",
    "        return 5\n",
    "    elif len(text.split()) > 10:\n",
    "        return 4\n",
    "    elif len(text.split()) > 5:\n",
    "        return 3\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def score_conversation_closing(text):\n",
    "    closing_words = ['thank', 'goodbye', 'summary', 'wrap up', 'conclude', 'farewell','fine','cool','end']\n",
    "    if any(word in text.lower() for word in closing_words):\n",
    "        return 5\n",
    "    elif len(text.split()) > 8:\n",
    "        return 4\n",
    "    elif len(text.split()) > 5:\n",
    "        return 3\n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "def refined_evaluate_dialogue_quality(text):\n",
    "    hesitation_words = ['uh', 'um', 'like', 'you know', 'hmm', 'er', 'ah']\n",
    "    hesitation_count = sum(text.lower().count(word) for word in hesitation_words)\n",
    "    sentiment = TextBlob(text).sentiment.polarity\n",
    "    if hesitation_count == 0 and len(text.split()) > 20 and sentiment > 0.3:\n",
    "        return 5\n",
    "    elif hesitation_count <= 2 and len(text.split()) > 15 and sentiment > 0.1:\n",
    "        return 4\n",
    "    elif hesitation_count <= 4 and sentiment > -0.2:\n",
    "        return 3\n",
    "    elif hesitation_count > 4 and len(text.split()) > 10 and sentiment > -0.5:\n",
    "        return 2\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "# Load and evaluate all topic files\n",
    "def evaluate_dialogue_segments(all_topic_files):\n",
    "    segment_scores = []\n",
    "    interactivity_scores = []\n",
    "    speaker_scores = []\n",
    "\n",
    "    for topic_file in all_topic_files:\n",
    "        if os.path.exists(topic_file):\n",
    "            topic_data = pd.read_csv(topic_file)\n",
    "            texts = topic_data['text'].fillna(\"\").values\n",
    "\n",
    "            # Step 1: Evaluate dialogue quality score\n",
    "            topic_data['refined_quality_score'] = topic_data['text'].apply(refined_evaluate_dialogue_quality)\n",
    "            average_score = topic_data['refined_quality_score'].mean()\n",
    "            segment_scores.append({\n",
    "                'file': os.path.basename(topic_file),\n",
    "                'average_quality_score': round(average_score, 2),\n",
    "                'num_utterances': len(topic_data)\n",
    "            })\n",
    "\n",
    "            # Step 2: Evaluate interactivity aspects\n",
    "            topic_management_score = score_topic_management(texts)\n",
    "            tone_appropriateness_score = score_tone_appropriateness(texts)\n",
    "            conversation_opening_score = score_conversation_opening(texts[0])\n",
    "            conversation_closing_score = score_conversation_closing(texts[-1])\n",
    "            interactivity_scores.append({\n",
    "                'file': os.path.basename(topic_file),\n",
    "                'topic_management_score': topic_management_score,\n",
    "                'tone_appropriateness_score': tone_appropriateness_score,\n",
    "                'conversation_opening_score': conversation_opening_score,\n",
    "                'conversation_closing_score': conversation_closing_score\n",
    "            })\n",
    "\n",
    "            # Step 3: Score each speaker's performance\n",
    "            speakers = topic_data['speaker'].unique()\n",
    "            for speaker in speakers:\n",
    "                speaker_data = topic_data[topic_data['speaker'] == speaker]\n",
    "                topic_management_score = score_topic_management(speaker_data['text'].values)\n",
    "                tone_appropriateness_score = score_tone_appropriateness(speaker_data['text'].values)\n",
    "                conversation_opening_score = score_conversation_opening(speaker_data['text'].values[0]) if len(speaker_data) > 0 else 0\n",
    "                conversation_closing_score = score_conversation_closing(speaker_data['text'].values[-1]) if len(speaker_data) > 0 else 0\n",
    "                speaker_scores.append({\n",
    "                    'speaker': speaker,\n",
    "                    'file': os.path.basename(topic_file),\n",
    "                    'topic_management_score': topic_management_score,\n",
    "                    'tone_appropriateness_score': tone_appropriateness_score,\n",
    "                    'conversation_opening_score': conversation_opening_score,\n",
    "                    'conversation_closing_score': conversation_closing_score\n",
    "                })\n",
    "\n",
    "    # Create DataFrames for all steps\n",
    "    segment_scores_df = pd.DataFrame(segment_scores)\n",
    "    interactivity_scores_df = pd.DataFrame(interactivity_scores)\n",
    "    speaker_scores_df = pd.DataFrame(speaker_scores)\n",
    "\n",
    "    return segment_scores_df, interactivity_scores_df, speaker_scores_df\n",
    "\n",
    "# Function to save the evaluation results to CSV\n",
    "def save_results(segment_scores_df, interactivity_scores_df, speaker_scores_df):\n",
    "    segment_scores_filename = 'your file name'\n",
    "    interactivity_scores_filename = 'your file name'\n",
    "    speaker_scores_filename = 'your file name'\n",
    "    \n",
    "    segment_scores_df.to_csv(segment_scores_filename, index=False)\n",
    "    interactivity_scores_df.to_csv(interactivity_scores_filename, index=False)\n",
    "    speaker_scores_df.to_csv(speaker_scores_filename, index=False)\n",
    "    \n",
    "    return segment_scores_filename, interactivity_scores_filename, speaker_scores_filename\n",
    "\n",
    "# Example usage\n",
    "all_topic_files = []  # Populate this with paths to the segmented dialogue CSV files\n",
    "# Evaluate and get the results\n",
    "dialogue_quality_scores, interactivity_scores, speaker_scores = evaluate_dialogue_segments(all_topic_files)\n",
    "# Save the results\n",
    "segment_scores_path, interactivity_scores_path, speaker_scores_path = save_results(dialogue_quality_scores, interactivity_scores, speaker_scores)\n",
    "\n",
    "# Paths to the results\n",
    "(segment_scores_path, interactivity_scores_path, speaker_scores_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

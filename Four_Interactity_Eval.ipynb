{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78ae2b4-c924-4c6a-a1d1-82a887509606",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a scoring function for the four interactivity aspects based on the provided definitions\n",
    "def score_interactivity_aspects(segment_texts):\n",
    "    # Initialize scores for each aspect\n",
    "    topic_management_score = 1\n",
    "    tone_appropriateness_score = 1\n",
    "    opening_score = 1\n",
    "    closing_score = 1\n",
    "\n",
    "    # Criteria for Topic Management: Presence of transitions and smooth flow\n",
    "    if any(text.lower() in [\"moving on\", \"next topic\", \"let's discuss\"] for text in segment_texts):\n",
    "        topic_management_score = 5  # Smooth topic management\n",
    "    elif any(\"so\" in text.lower() or \"now\" in text.lower() for text in segment_texts):\n",
    "        topic_management_score = 4  # Moderate transitions\n",
    "\n",
    "    # Criteria for Tone Choice Appropriateness: Professional, polite, or suitable expressions\n",
    "    if all(\"please\" in text.lower() or \"thank you\" in text.lower() for text in segment_texts):\n",
    "        tone_appropriateness_score = 5  # Very appropriate tone\n",
    "    elif any(\"please\" in text.lower() or \"thanks\" in text.lower() for text in segment_texts):\n",
    "        tone_appropriateness_score = 4  # Generally appropriate tone\n",
    "\n",
    "    # Criteria for Conversation Opening: Look for welcoming or context-setting phrases\n",
    "    if any(text.lower().startswith((\"hi\", \"hello\", \"good\", \"so\")) for text in segment_texts):\n",
    "        opening_score = 5  # Clear, contextually appropriate opening\n",
    "    elif any(text.lower().startswith((\"okay\", \"well\", \"now\")) for text in segment_texts):\n",
    "        opening_score = 4  # Somewhat effective opening\n",
    "\n",
    "    # Criteria for Conversation Closing: Look for concluding or farewell phrases\n",
    "    if any(text.lower().startswith((\"thanks\", \"thank you\", \"bye\", \"okay, that's it\")) for text in segment_texts):\n",
    "        closing_score = 5  # Clear, polite farewell\n",
    "    elif any(text.lower().startswith((\"so\", \"alright\", \"okay\")) for text in segment_texts):\n",
    "        closing_score = 4  # Partial closing\n",
    "\n",
    "    return topic_management_score, tone_appropriateness_score, opening_score, closing_score\n",
    "\n",
    "# Calculate scores for each aspect in the first dialogue\n",
    "first_dialogue_scores = [score_interactivity_aspects(data[data['segment'] == seg_id]['text'].tolist())\n",
    "                         for seg_id in data['segment'].unique()]\n",
    "\n",
    "# Average scores for each interactivity aspect in the first dialogue\n",
    "avg_first_topic_management = sum([score[0] for score in first_dialogue_scores]) / len(first_dialogue_scores)\n",
    "avg_first_tone_appropriateness = sum([score[1] for score in first_dialogue_scores]) / len(first_dialogue_scores)\n",
    "avg_first_opening = sum([score[2] for score in first_dialogue_scores]) / len(first_dialogue_scores)\n",
    "avg_first_closing = sum([score[3] for score in first_dialogue_scores]) / len(first_dialogue_scores)\n",
    "\n",
    "# Calculate scores for each aspect in the second dialogue\n",
    "second_dialogue_scores = [score_interactivity_aspects(data_new[data_new['segment'] == seg_id]['text'].tolist())\n",
    "                          for seg_id in data_new['segment'].unique()]\n",
    "\n",
    "# Average scores for each interactivity aspect in the second dialogue\n",
    "avg_second_topic_management = sum([score[0] for score in second_dialogue_scores]) / len(second_dialogue_scores)\n",
    "avg_second_tone_appropriateness = sum([score[1] for score in second_dialogue_scores]) / len(second_dialogue_scores)\n",
    "avg_second_opening = sum([score[2] for score in second_dialogue_scores]) / len(second_dialogue_scores)\n",
    "avg_second_closing = sum([score[3] for score in second_dialogue_scores]) / len(second_dialogue_scores)\n",
    "\n",
    "# Display the average scores for both dialogues\n",
    "first_dialogue_results = {\n",
    "    \"Topic Management\": avg_first_topic_management,\n",
    "    \"Tone Appropriateness\": avg_first_tone_appropriateness,\n",
    "    \"Conversation Opening\": avg_first_opening,\n",
    "    \"Conversation Closing\": avg_first_closing\n",
    "}\n",
    "\n",
    "second_dialogue_results = {\n",
    "    \"Topic Management\": avg_second_topic_management,\n",
    "    \"Tone Appropriateness\": avg_second_tone_appropriateness,\n",
    "    \"Conversation Opening\": avg_second_opening,\n",
    "    \"Conversation Closing\": avg_second_closing\n",
    "}\n",
    "\n",
    "first_dialogue_results, second_dialogue_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f169effe-6bd6-44f3-ac14-22cdd5445efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the results of both dialogues\n",
    "import pandas as pd\n",
    "\n",
    "# Data for first and second dialogue\n",
    "dialogue_results_data = {\n",
    "    \"Aspect\": [\"Topic Management\", \"Tone Appropriateness\", \"Conversation Opening\", \"Conversation Closing\"],\n",
    "    \"First Dialogue\": [first_dialogue_results[\"Topic Management\"], first_dialogue_results[\"Tone Appropriateness\"],\n",
    "                       first_dialogue_results[\"Conversation Opening\"], first_dialogue_results[\"Conversation Closing\"]],\n",
    "    \"Second Dialogue\": [second_dialogue_results[\"Topic Management\"], second_dialogue_results[\"Tone Appropriateness\"],\n",
    "                        second_dialogue_results[\"Conversation Opening\"], second_dialogue_results[\"Conversation Closing\"]]\n",
    "}\n",
    "\n",
    "# Create the DataFrame\n",
    "dialogue_results_df = pd.DataFrame(dialogue_results_data)\n",
    "\n",
    "# Save to CSV\n",
    "file_path = '/mnt/data/Dialogue_Interactivity_Scores.csv'\n",
    "dialogue_results_df.to_csv(file_path, index=False)\n",
    "\n",
    "file_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41deb2b-f6f2-4ae9-96e4-18f29c6974b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
